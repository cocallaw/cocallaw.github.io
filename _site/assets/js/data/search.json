[
  
  {
    "title": "Export BitLocker Keys from Entra with GraphPowerShell",
    "url": "/posts/Export-Bitlocker-Keys-from-Entra/",
    "categories": "PowerShell, Azure, Microsoft Graph",
    "tags": "powershell, azure, crowdstrike, bitlocker, entra, microsoft-graph",
    "date": "2025-05-01 13:00:00 -0400",
    





    
    "snippet": "On the day of the CrowdStrike outage, countless Windows devices across the world became unstable—many of them failing to boot or respond. For machines running in Azure that were still powered on bu...",
    "content": "On the day of the CrowdStrike outage, countless Windows devices across the world became unstable—many of them failing to boot or respond. For machines running in Azure that were still powered on but inaccessible, administrators needed one critical thing to attempt repair: the BitLocker recovery key.If your Azure-based Windows VMs were registered with Intune (now part of Microsoft Entra), these recovery keys were likely stored securely in your tenant. With PowerShell and Microsoft Graph, I was able to retrieve them quickly and at scale.The Problem  Azure VMs were running but inaccessible due to OS corruption.  BitLocker encryption was enabled on the OS disk.  Admins needed recovery keys to unlock drives and begin repair.  Machines were previously registered with Microsoft Entra / Intune.The Solution: PowerShell + Microsoft GraphThe following PowerShell script automates the retrieval of BitLocker recovery keys for a list of VM names. It queries Microsoft Graph to find devices by name, then pulls their associated keys.  ✅ Pre-req: The VMs must be enrolled in Intune/Entra, and your account must have Device.Read.All and BitLockerKey.Read.All permissions in Microsoft Graph.Full PowerShell Script# Optional: select Azure subscriptionSelect-AzSubscription -Subscription '&lt;your-subscription-id&gt;'# Manually define the names of Azure VMs you want to check$vmNames = @(    \"VM-Prod-01\",    \"VM-Prod-02\",    \"VM-Finance-01\")# Connect to Microsoft Graph with necessary scopesConnect-MgGraph -Scopes \"Device.Read.All\", \"BitLockerKey.Read.All\"# Initialize list of matching devices$devices = @()foreach ($vmName in $vmNames) {    Write-Host \"Searching for device: $vmName\"    $devices += Get-MgDevice -Filter \"displayName eq '$vmName'\"}# Initialize result list$deviceRecoveryKeys = @()# Retrieve BitLocker recovery keysforeach ($device in $devices) {    $recoveryKeys = Get-MgInformationProtectionBitlockerRecoveryKey -Filter \"deviceId eq '$($device.DeviceId)'\"    foreach ($key in $recoveryKeys) {        $deviceRecoveryKeys += [PSCustomObject]@{            DeviceName  = $device.DisplayName            RecoveryKey = (Get-MgInformationProtectionBitlockerRecoveryKey -BitlockerRecoveryKeyId $key.Id -Property key).key        }    }}# Output the recovery keys$deviceRecoveryKeys | Format-Table -AutoSizeSample OutputDeviceName     RecoveryKey-----------    ---------------------------------------------------------VM-Prod-01     A123-XXXX-XXXX-XXXX-XXXX-XXXX-XXXX-XXXXVM-Prod-02     B456-YYYY-YYYY-YYYY-YYYY-YYYY-YYYY-YYYYVM-Finance-01  C789-ZZZZ-ZZZZ-ZZZZ-ZZZZ-ZZZZ-ZZZZ-ZZZZNotes  This script targets any Intune/Entra-registered Windows VM—not just those in Azure Virtual Desktop.  Recovery keys are only available if the device was properly enrolled and reporting compliance.  Permissions must be delegated or granted through an app registration with the appropriate Graph scopesFinal ThoughtsThis was a good reminder that recovery isn’t just about backups—it’s also about access. PowerShell and Microsoft Graph made it possible to recover quickly during the CrowdStrike outage by tapping into the organization’s existing device inventory and key storage.If you find yourself in a similar emergency, I hope this script gives you a head start.Let me know if you need help modifying it to support bulk export, error handling, or integration with incident response tools."
  },
  
  {
    "title": "Automating Container Builds with GitHub Actions for Upstream Changes",
    "url": "/posts/Automating-Container-Builds-for-Upstream-Changes/",
    "categories": "GitHub Actions, Docker, Automation, DevOps",
    "tags": "DevOps, Automation",
    "date": "2025-05-01 13:00:00 -0400",
    





    
    "snippet": "Maintaining container images that rely on upstream projects can be time-consuming if you’re manually checking for updates and rebuilding them. Thankfully, GitHub Actions makes it easy to automate t...",
    "content": "Maintaining container images that rely on upstream projects can be time-consuming if you’re manually checking for updates and rebuilding them. Thankfully, GitHub Actions makes it easy to automate these tasks and improve operational efficiency in your homelab or production workflows.In this post, I’ll walk through how I use a GitHub Actions workflow to automatically check for updates to an upstream Docker image, and trigger a build and push only if a new version is available. This kind of automation saves time, reduces human error, and keeps my environment reliably up to date.Why Automate Container Builds?If you’re maintaining a custom container that wraps or extends functionality from an upstream project (like Tailscale, Nginx, or Node.js), you’ll often want to:  Track upstream releases.  Rebuild your container with the new version.  Push the updated image to Docker Hub or a private registry.  Optionally commit a version change back to your repo for tracking.Doing all this manually is inefficient. Automating this with GitHub Actions ensures consistency and frees you to focus on more important tasks.The WorkflowHere’s a breakdown of the GitHub Actions workflow I use. It:  Runs every 3 days or on manual trigger.  Checks the latest stable tag of the upstream container.  Compares it against images already published.  Builds and pushes multi-arch images only if a new version exists.  Commits a version file update for visibility.Workflow BreakdownLet’s walk through what each section of the workflow does and how it contributes to the automation process.1. Triggerson:  schedule:    - cron: '0 0 */3 * *'  workflow_dispatch:  schedule: Runs the workflow automatically every 3 days.  workflow_dispatch: Allows you to manually trigger the workflow from the GitHub UI.2. Permissionspermissions:  contents: writeThis grants the workflow permission to make commits to the repository, which is necessary to update and push the version file.3. Job: check-and-buildThe entire automation is contained in a single job that runs on the latest Ubuntu GitHub Actions runner.Step: Checkout Repo- name: Checkout repo  uses: actions/checkout@v3This pulls down your repository code so that subsequent steps can read/write files like upstream-version.txt.Step: Get Latest Upstream Version- name: Get latest upstream version  id: upstream  run: |    VERSION=$(curl -s ...  Uses Docker Hub’s API to fetch the latest stable tag from an upstream image.  Outputs the latest version as steps.upstream.outputs.version.Step: Check for Existing Image- name: Check if image already exists  id: check  run: |    if docker manifest inspect ...  Uses docker manifest inspect to check whether a container image for this version already exists in your Docker Hub repo.  Sets a flag build_needed to true or false.Conditional Build StepsThe following steps are only run if a new version is detected:  Set up emulation support (QEMU) for building multi-architecture containers.  Set up Docker Buildx for advanced build features.  Log into Docker Hub using credentials stored in GitHub Secrets.  Build and push the container using the new version as a tag.Step: Commit Version Update- name: Commit version update  run: |    echo \"$\" &gt; upstream-version.txt    ...This writes the new version to a file, commits it, and pushes it to your GitHub repo. This gives you a version history and a way to confirm that the build occurred.Secrets You Will Need  DOCKERHUB_USERNAME: Your Docker Hub username.  DOCKERHUB_TOKEN: A Docker Hub access token with write permissions.You can create a token here and add the secrets via your repository’s Settings &gt; Secrets and variables.The YAML Workflowname: Auto Build &amp; Publish Containeron:  schedule:    - cron: '0 0 */3 * *'  # Every 3 days at 00:00 UTC  workflow_dispatch:permissions:  contents: write  # Needed to commit version filejobs:  check-and-build:    runs-on: ubuntu-latest    steps:      - name: Checkout repo        uses: actions/checkout@v3      - name: Get latest upstream version        id: upstream        run: |          VERSION=$(curl -s https://registry.hub.docker.com/v2/repositories/tailscale/tailscale/tags/?page_size=100 \\            | jq -r '.results[].name' \\            | grep -E '^v[0-9]+\\.[0-9]+(\\.[0-9]+)?$' \\            | sort -V \\            | tail -n1)          echo \"version=$VERSION\" &gt;&gt; \"$GITHUB_OUTPUT\"      - name: Check if image already exists        id: check        run: |          if docker manifest inspect $/my-custom-image:$ &gt; /dev/null 2&gt;&amp;1; then            echo \"build_needed=false\" &gt;&gt; $GITHUB_OUTPUT          else            echo \"build_needed=true\" &gt;&gt; $GITHUB_OUTPUT          fi      - name: Set up QEMU        if: steps.check.outputs.build_needed == 'true'        uses: docker/setup-qemu-action@v2      - name: Set up Docker Buildx        if: steps.check.outputs.build_needed == 'true'        uses: docker/setup-buildx-action@v2      - name: Login to DockerHub        if: steps.check.outputs.build_needed == 'true'        uses: docker/login-action@v2        with:          username: $          password: $      - name: Build and push container        if: steps.check.outputs.build_needed == 'true'        uses: docker/build-push-action@v3        with:          context: ./docker          build-args: |            BASE_TAG=$          platforms: linux/amd64,linux/arm64          push: true          tags: |            $/my-custom-image:latest            $/my-custom-image:$      - name: Commit version update        if: steps.check.outputs.build_needed == 'true'        run: |          echo \"$\" &gt; upstream-version.txt          git config user.name \"github-actions[bot]\"          git config user.email \"github-actions[bot]@users.noreply.github.com\"          git add upstream-version.txt          git commit -m \"Update base image to version $\"          git pushFinal ThoughtsAutomating container builds with GitHub Actions is a powerful way to keep your images up to date without manual intervention. This workflow can be adapted for any upstream project, and you can customize it further based on your needs.  Consider adding notifications (e.g., Slack, email) to alert you when a new version is built.  You can also extend the workflow to run tests against the new image before pushing it.  Explore other GitHub Actions to enhance your CI/CD pipeline."
  },
  
  {
    "title": "Create Confidential Compute Capable Custom Images from Windows CVMs",
    "url": "/posts/Creating-Confidentail-Compute-Images-from-CVMs/",
    "categories": "Confidential Compute",
    "tags": "images",
    "date": "2025-01-06 12:00:00 -0500",
    





    
    "snippet": "Confidential Compute Custom ImagesCreating a custom image from an Azure Confidential Compute VM (CVM) requires following a different process than you would for a regular Azure VM. This is due to th...",
    "content": "Confidential Compute Custom ImagesCreating a custom image from an Azure Confidential Compute VM (CVM) requires following a different process than you would for a regular Azure VM. This is due to the design of CVMs, which utilize an OS disk and a small encrypted data disk that contains the VM Guest State(VMGS) information. As a result, using the Capture button in the Azure portal or the New-AzImage command in Azure PowerShell will not produce the desired results.This process to create a custom image from a CVM is necessary so that the captured image is free of and VM Guest State information and the correct properties are set for the image version and reference in a Azure Compute Gallery.The steps outlined below require that you have access to the Azure Subscriptions containing the resources, and the current version of both Azure CLI and AzCopy installed. Commands were tested using Azure CLI from a Powershell Core session.  This process to create a custom image is for an existing Windows based CVM using with Confidential OS disk encryption enabled using either PMK or CMK.Prepare the CVM OS for CaptureOnce the customization of the Windows OS is complete, the next step is to Disable BitLocker, wait for the decryption to complete, and then run Sysprep.To disable BitLocker and check the decryption status of the OS disk, you can use the following commands in an elevated Command Prompt.# Disable BitLockermanage-bde -off C:# Check the decryption statusmanage-bde -status C:When the decryption status returns as Fully Decrypted, Sysprep can now be run. Selecting Generalize and Shutdown as the options.Creating the Custom ImageCollect OS Disk InformationThe first step is to make sure the CVM the image is being created from is fully deallocated and then collect information about the OS disk. To do so we will need to know the resource group name, VM name, and region that the CVM is located in, we will set these as variables for easy reference.$region = \"North Europe\"$resourceGroupName = \"rg-custimg-lab-01\"$vmName = \"custcvm-01\"With the variables set, verify the VM is deallocated# Deallocate the VMaz vm deallocate --name $vmname --resource-group $resourceGroupName# Collect the OS Disk information$disk_name = (az vm show --name $vmname --resource-group $resourceGroupName | jq -r .storageProfile.osDisk.name)$disk_url = (az disk grant-access --duration-in-seconds 3600 --name $disk_name --resource-group $resourceGroupName | jq -r .accessSas)Create a Storage Account for the VHDNext, create a storage account, this will be used to store the exported VHD of the CVMs OS disk before it is uploaded to the Compute Gallery. For this part of the process, you will need to know the name of the Storage Account and Container that will be created.$storageAccountName = \"stgcvmvhd01\"$storageContainerName = \"cvmimages\"$referenceVHD = \"${vmName}.vhd\"Create the Storage Account and Container# Create Storage Accountaz storage account create --resource-group ${resourceGroupName} --name ${storageAccountName} --location $region --sku \"Standard_LRS\"# Create a container in the Storage Accountaz storage container create --name $storageContainerName --account-name $storageAccountName --resource-group $resourceGroupNameWith the Storage Account and Container created, generate a Shared Access Signature (SAS) token to upload the disk image to the container. Be sure to set the expiry date to a date in the future.# Generate a SAS token for the container$container_sas=(az storage container generate-sas --name $storageContainerName --account-name $storageAccountName --auth-mode key --expiry 2025-01-01 --https-only --permissions dlrw -o tsv)Using the SAS token and information collected, the VHD can now be exported to the Storage Account using AzCopy.# Build the Blob URL$blob_url=\"https://${storageAccountName}.blob.core.windows.net/$storageContainerName/$referenceVHD\"# Export the VHD using AzCopyazcopy copy \"$disk_url\" \"${blob_url}?${container_sas}\"Upload the Image to a Compute GalleryWith the VHD successfully exported to the Storage Account, the next step is to create an image definition in the Compute Gallery and upload the VHD to the gallery as a new version. For this part of the process, you will need to know the name of the Compute Gallery, Image Definition, Offer, Publisher, SKU, and Version number that will be created.$galleryName = \"acglabneu01\"$imageDefinitionName = \"cvmimage01\"$OfferName = \"offername01\"$PublisherName = \"pubname01\"$SkuName = \"skuname01\"$galleryImageVersion = \"1.0.0\"If a Compute Gallery does not already exist, create one using the following command, and create an Image Definition that has the required features and parameters set for Confidential VM support.# Create the Compute Galleryaz sig create --resource-group $resourceGroupName --gallery-name $galleryName# Create the Image Definitionaz sig image-definition create --resource-group  $resourceGroupName --location $region --gallery-name $galleryName --gallery-image-definition $imageDefinitionName --publisher $PublisherName --offer $OfferName --sku $SkuName --os-type windows --os-state Generalized --hyper-v-generation V2  --features SecurityType=ConfidentialVMSupportedTo upload the VHD to the Compute Gallery, the ID of the Storage Account that contains tehVHD is required when creating the image version. This can be obtained using the following command.# Get the Storage Account ID$storageAccountId=(az storage account show --name $storageAccountName --resource-group $resourceGroupName | jq -r .id)With everything in place, the final step is to create the image version in the Compute Gallery using the VHD that was exported from the CVM.# Create the Image Versionaz sig image-version create --resource-group $resourceGroupName --gallery-name $galleryName --gallery-image-definition $imageDefinitionName --gallery-image-version $galleryImageVersion --os-vhd-storage-account $storageAccountId --os-vhd-uri $blob_urlThe Full Image Export ProcessBelow is the full process to export the OS disk from the CVM, create the image, and upload it to the Compute Gallery.# Set Variables$region = \"North Europe\"$resourceGroupName = \"rg-custimg-lab-01\"$vmName = \"custcvm-01\"$storageAccountName = \"stgcvmvhd01\"$storageContainerName = \"cvmimages\"$referenceVHD = \"${vmName}.vhd\"$galleryName = \"acglabneu01\"$imageDefinitionName = \"cvmimage01\"$OfferName = \"offername01\"$PublisherName = \"pubname01\"$SkuName = \"skuname01\"$galleryImageVersion = \"1.0.0\"# Deallocate the VMaz vm deallocate --name $vmName --resource-group $resourceGroupName# Collect the OS Disk information$disk_name = (az vm show --name $vmName --resource-group $resourceGroupName | jq -r .storageProfile.osDisk.name)$disk_url = (az disk grant-access --duration-in-seconds 3600 --name $disk_name --resource-group $resourceGroupName | jq -r .accessSas)# Create Storage Accountaz storage account create --resource-group ${resourceGroupName} --name ${storageAccountName} --location $region --sku \"Standard_LRS\"# Create a container in the Storage Accountaz storage container create --name $storageContainerName --account-name $storageAccountName --resource-group $resourceGroupName# Generate a SAS token for the container$container_sas=(az storage container generate-sas --name $storageContainerName --account-name $storageAccountName --auth-mode key --expiry 2025-01-01 --https-only --permissions dlrw -o tsv)# Build the Blob URL$blob_url=\"https://${storageAccountName}.blob.core.windows.net/$storageContainerName/$referenceVHD\"# Export the VHD using AzCopyazcopy copy \"$disk_url\" \"${blob_url}?${container_sas}\"# Create the Compute Galleryaz sig create --resource-group $resourceGroupName --gallery-name $galleryName# Create the Image Definitionaz sig image-definition create --resource-group  $resourceGroupName --location $region --gallery-name $galleryName --gallery-image-definition $imageDefinitionName --publisher $PublisherName --offer $OfferName --sku $SkuName --os-type windows --os-state Generalized --hyper-v-generation V2  --features SecurityType=ConfidentialVMSupported# Get the Storage Account ID$storageAccountId=(az storage account show --name $storageAccountName --resource-group $resourceGroupName | jq -r .id)# Create the Image Versionaz sig image-version create --resource-group $resourceGroupName --gallery-name $galleryName --gallery-image-definition $imageDefinitionName --gallery-image-version $galleryImageVersion --os-vhd-storage-account $storageAccountId --os-vhd-uri $blob_url"
  },
  
  {
    "title": "Creating Confidential Compute Capable Custom Images from Standard Windows VMs",
    "url": "/posts/Creating-Confidential-Compute-Capable-Custom-Images/",
    "categories": "Confidential Compute",
    "tags": "images",
    "date": "2025-01-05 12:00:00 -0500",
    





    
    "snippet": "Confidential Compute and Custom ImagesCreating a custom image that can be used to create Azure Confidential Compute (ACC) VMs is similar to creating a standard custom image, but with a slight twist...",
    "content": "Confidential Compute and Custom ImagesCreating a custom image that can be used to create Azure Confidential Compute (ACC) VMs is similar to creating a standard custom image, but with a slight twist when it comes to how the image is captured. This post covers how to create a custom image that could be used to provision a new ACC VM using either Customer Managed Key (CMK) or Platform Managed Key (PMK) encryption in any Azure region that has ACC capable AMD VM SKUs.It is important to use the proper settings when creating the VM used to generate the custom image and capture the custom image, so that settings and features such as BitLocker are not enabled, which would require additional steps before capturing and possibly cause issues when using the captured image to provision a new CVM.The steps outlined below require that you have access to the Azure Subscriptions containing the resources, and the current version of Azure PowerShell installed. Commands were tested using Azure PowerShell from a Powershell Core session.Creating the VM for Custom Image Capture      From the Azure Portal, Select Virtual Machine and Create New VM        On the Instance Detail page set Security Type to Standard, and select a non-ACC VM SKU            On the Disks tab, set Key Management to Platform-managed Key and leave Encryption at host unchecked            Once the Custom Image VM has been deployed, connect to the machine and perform any customization tasks required.        When all customizations are complete, run Sysprep with OOBE, Generalize and Shutdown selected            Once Sysprep has completed, the VM is ready to be captured  Capture the Custom ImageFrom an Azure PowerShell session connected to the Subscription that contains the Custom Image VM, set the proper values for the variables $vmName, $rgName, $location and $imageName.$vmName = \"customvm01\"$rgNameCustImg = \"rg-custom-img-01\"$location = \"North Europe\"$imageName = \"image-01\"With the variables set run the following commands to create a Manged Image resource from the OS disk of the Custom Image VM.# Verify that the VM is deallocatedStop-AzVM -ResourceGroupName $rgNameCustImg -Name $vmName -Force# Set the status of the VM to generalizedSet-AzVm -ResourceGroupName $rgNameCustImg -Name $vmName -Generalized# Store the VM details in a variable$vm = Get-AzVM -Name $vmName -ResourceGroupName $rgNameCustImg# Create the image configuration $imageConfig = New-AzImageConfig -Location $location -SourceVirtualMachineId $vm.Id -HyperVGeneration V2# Create an image from the VMNew-AzImage -ImageName $imageName -ResourceGroupName $rgNameCustImg -Image $imageConfigImporting the Custom Image into Azure Compute GalleryAzure PortalIn the Azure Compute Gallery create a new Image Definition, with the Security Type set to Trusted launch and confidential VM supportedOn the next page select the Managed Image Resource to import to the Compute Gallery for the Image DefinitionAzure PowerShellTo import the Managed Image into the Compute Gallery, there first needs to be a new Image Definition created and then the Managed Image imported as a new version of the image definition.To create the new Image Definition, set the following variables$rgNameACG  = \"rg-compute-gallery-01\"$location = \"North Europe\"$galleryName = \"acgallery01\"$galleryImageDefinitionName = \"Def01\"$publisherName = \"Publisher01\"$offerName = \"Offer01\"$skuName = \"Win11-24H2\"$description = \"Windows 11 24H2\"# Variables to set the features of the Image Definition$ConfidentialVMSupported = @{Name='SecurityType';Value='TrustedLaunchAndConfidentialVmSupported'}$IsHibernateSupported = @{Name='IsHibernateSupported';Value='False'}$features = @($ConfidentialVMSupported,$IsHibernateSupported)With the variables set, run the following command to create the new Image Definition in the Compute GalleryNew-AzGalleryImageDefinition -ResourceGroupName $rgNameACG -GalleryName $galleryName -Name $galleryImageDefinitionName -Location $location -Publisher $publisherName -Offer $offerName -Sku $skuName -OsState \"Generalized\" -OsType \"Windows\" -Description $description -Feature $features -HyperVGeneration \"V2\"Now that there is an Image Definition in the Compute Gallery, the Managed Image that was created from the Custom Image VM can be imported as a version of the Image Definition. To do this, first the Resource ID of the Managed Image needs to be retrieved.$imageRID = (Get-AzImage -ResourceGroupName $rgNameCustImg -ImageName $imageName).Id$rgNameACG = \"rg-compute-gallery-01\"$location = \"North Europe\"$galleryName = \"acgallery01\"$galleryImageDefinitionName = \"Def01\"$galleryImageVersionName = \"0.0.1\"$sourceImageId = $imageRID$storageAccountType = \"Premium_LRS\"New-AzGalleryImageVersion -ResourceGroupName $rgNameACG -GalleryName $galleryName -GalleryImageDefinitionName $galleryImageDefinitionName -Name $galleryImageVersionName -Location $location -StorageAccountType $storageAccountType -SourceImageId $sourceImageIdOnce the image has been imported and the new Definition created in the Compute Gallery, you can utilizes either the Resource ID of the new Image Definition as a parameter in a template file or create new Confidential VMs from the Compute Gallery using the Azure Portal."
  }
  
]

